{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading 2018 train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape (5526, 8)\n",
      "B shape (873, 8)\n",
      "C shape (299, 8)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/data.pkl', 'rb') as pf:\n",
    "    objs = pickle.load(pf)\n",
    "\n",
    "grammar_dic = objs[0]\n",
    "df_18_A_train = objs[3]    # using RecResult\n",
    "df_18_B_train = objs[4]\n",
    "df_18_C_train = objs[5]\n",
    "\n",
    "print('A shape {}'.format(df_18_A_train.shape))\n",
    "print('B shape {}'.format(df_18_B_train.shape))\n",
    "print('C shape {}'.format(df_18_C_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_18_train = pd.concat([df_18_A_train, df_18_B_train, df_18_C_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6410, 12)\n"
     ]
    }
   ],
   "source": [
    "recode = lambda x: 1 if x=='correct' else 0\n",
    "df_18_train['language'] = df_18_train['language'].apply(recode)\n",
    "df_18_train['meaning'] = df_18_train['meaning'].apply(recode)\n",
    "\n",
    "# load various types of features\n",
    "# grammar error count\n",
    "dfA = pd.read_csv('../data/processed/df18_A_train_grmerror.csv')\n",
    "dfB = pd.read_csv('../data/processed/df18_B_train_grmerror.csv')\n",
    "dfC = pd.read_csv('../data/processed/df18_C_train_grmerror.csv')\n",
    "train_grmerr = pd.concat([dfA, dfB, dfC])\n",
    "\n",
    "# print(df_17_test_vecsim.shape)\n",
    "print(train_grmerr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form a DF for modeling\n",
    "- df_18_X, only using Id, language, and meaning cols\n",
    "- using Id to merge other features DFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1/24/2018 Huy's updated features (including edit pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6671, 195)\n",
      "Index(['Id', 'ppl-ref', 'ppl-ref_pos', 'ppl-ref_prod', 'ppl-ref_dep',\n",
      "       'ppl-prompt', 'ppl-prompt_pos', 'ppl-correct', 'ppl-correct_pos',\n",
      "       'ppl-correct_prod',\n",
      "       ...\n",
      "       'length_unknown-ratio', 'length_sounds', 'length_sounds-ratio',\n",
      "       'prompt_missing', 'prompt_missing-pct', 'prompt_DT', 'prompt_IN',\n",
      "       'prompt_MD', 'prompt_NN', 'prompt_VB'],\n",
      "      dtype='object', length=195)\n"
     ]
    }
   ],
   "source": [
    "dfA = pd.read_csv('../data/processed/Huy/scst2_training_data_A_text_features.csv', sep='\\t')\n",
    "dfB = pd.read_csv('../data/processed/Huy/scst2_training_data_B_text_features.csv', sep='\\t')\n",
    "dfC = pd.read_csv('../data/processed/Huy/scst2_training_data_C_text_features.csv', sep='\\t')\n",
    "\n",
    "train_huy = pd.concat([dfA, dfB, dfC])\n",
    "train_huy.rename(columns={'ID' : 'Id'}, inplace=True)\n",
    "\n",
    "train_huy = train_huy.drop(['CLASS'], axis=1)\n",
    "print(train_huy.shape)\n",
    "print(train_huy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_ml_df(df_main, df_grmerr, df_huy):\n",
    "    df_ml = df_main[['Id', 'language', 'meaning']]\n",
    "    df_ml = pd.merge(df_ml, df_grmerr, on='Id')\n",
    "    df_ml = pd.merge(df_ml, df_huy, on='Id')\n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 2018 train DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tain_ml shape: (6383, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>language</th>\n",
       "      <th>meaning</th>\n",
       "      <th>ofto_error_count</th>\n",
       "      <th>Spell</th>\n",
       "      <th>Article_a_an_error_count</th>\n",
       "      <th>sva_error_count</th>\n",
       "      <th>RuleRepeatedLinkWords_error_count</th>\n",
       "      <th>Verbform_error_count</th>\n",
       "      <th>noun_error_count</th>\n",
       "      <th>...</th>\n",
       "      <th>length_unknown-ratio</th>\n",
       "      <th>length_sounds</th>\n",
       "      <th>length_sounds-ratio</th>\n",
       "      <th>prompt_missing</th>\n",
       "      <th>prompt_missing-pct</th>\n",
       "      <th>prompt_DT</th>\n",
       "      <th>prompt_IN</th>\n",
       "      <th>prompt_MD</th>\n",
       "      <th>prompt_NN</th>\n",
       "      <th>prompt_VB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.0</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.0</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6383.0</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "      <td>6383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3314.567915</td>\n",
       "      <td>0.691838</td>\n",
       "      <td>0.858687</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.230299</td>\n",
       "      <td>0.952217</td>\n",
       "      <td>1.331662</td>\n",
       "      <td>0.296593</td>\n",
       "      <td>0.153063</td>\n",
       "      <td>0.078490</td>\n",
       "      <td>0.073476</td>\n",
       "      <td>0.303149</td>\n",
       "      <td>0.252389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1924.820882</td>\n",
       "      <td>0.461770</td>\n",
       "      <td>0.348371</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035383</td>\n",
       "      <td>0.127802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.156439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.291150</td>\n",
       "      <td>0.213324</td>\n",
       "      <td>1.578256</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.360076</td>\n",
       "      <td>0.268962</td>\n",
       "      <td>0.260937</td>\n",
       "      <td>0.459655</td>\n",
       "      <td>0.434417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1662.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3282.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4981.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6698.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id     language      meaning  ofto_error_count   Spell  \\\n",
       "count  6383.000000  6383.000000  6383.000000       6383.000000  6383.0   \n",
       "mean   3314.567915     0.691838     0.858687          0.000313     0.0   \n",
       "std    1924.820882     0.461770     0.348371          0.017700     0.0   \n",
       "min       4.000000     0.000000     0.000000          0.000000     0.0   \n",
       "25%    1662.500000     0.000000     1.000000          0.000000     0.0   \n",
       "50%    3282.000000     1.000000     1.000000          0.000000     0.0   \n",
       "75%    4981.500000     1.000000     1.000000          0.000000     0.0   \n",
       "max    6698.000000     1.000000     1.000000          1.000000     0.0   \n",
       "\n",
       "       Article_a_an_error_count  sva_error_count  \\\n",
       "count               6383.000000      6383.000000   \n",
       "mean                   0.001253         0.016607   \n",
       "std                    0.035383         0.127802   \n",
       "min                    0.000000         0.000000   \n",
       "25%                    0.000000         0.000000   \n",
       "50%                    0.000000         0.000000   \n",
       "75%                    0.000000         0.000000   \n",
       "max                    1.000000         1.000000   \n",
       "\n",
       "       RuleRepeatedLinkWords_error_count  Verbform_error_count  \\\n",
       "count                             6383.0           6383.000000   \n",
       "mean                                 0.0              0.000627   \n",
       "std                                  0.0              0.025027   \n",
       "min                                  0.0              0.000000   \n",
       "25%                                  0.0              0.000000   \n",
       "50%                                  0.0              0.000000   \n",
       "75%                                  0.0              0.000000   \n",
       "max                                  0.0              1.000000   \n",
       "\n",
       "       noun_error_count     ...       length_unknown-ratio  length_sounds  \\\n",
       "count       6383.000000     ...                     6383.0    6383.000000   \n",
       "mean           0.024440     ...                        0.0       5.230299   \n",
       "std            0.156439     ...                        0.0       2.291150   \n",
       "min            0.000000     ...                        0.0       1.000000   \n",
       "25%            0.000000     ...                        0.0       4.000000   \n",
       "50%            0.000000     ...                        0.0       5.000000   \n",
       "75%            0.000000     ...                        0.0       6.000000   \n",
       "max            2.000000     ...                        0.0      89.000000   \n",
       "\n",
       "       length_sounds-ratio  prompt_missing  prompt_missing-pct    prompt_DT  \\\n",
       "count          6383.000000     6383.000000         6383.000000  6383.000000   \n",
       "mean              0.952217        1.331662            0.296593     0.153063   \n",
       "std               0.213324        1.578256            0.338235     0.360076   \n",
       "min               0.000000        0.000000            0.000000     0.000000   \n",
       "25%               1.000000        0.000000            0.000000     0.000000   \n",
       "50%               1.000000        1.000000            0.200000     0.000000   \n",
       "75%               1.000000        2.000000            0.500000     0.000000   \n",
       "max               1.000000        9.000000            1.000000     1.000000   \n",
       "\n",
       "         prompt_IN    prompt_MD    prompt_NN    prompt_VB  \n",
       "count  6383.000000  6383.000000  6383.000000  6383.000000  \n",
       "mean      0.078490     0.073476     0.303149     0.252389  \n",
       "std       0.268962     0.260937     0.459655     0.434417  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     1.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 208 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NA: 0\n"
     ]
    }
   ],
   "source": [
    "train_ml = gen_ml_df(df_18_train, train_grmerr, train_huy)\n",
    "print('tain_ml shape: {}'.format(train_ml.shape))\n",
    "display(train_ml.describe())\n",
    "print('#NA: {}'.format(train_ml.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis\n",
    "Only show |R| more than $CORR_{CUT}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ppl-ref              0.299982\n",
       "ppl-ref_pos          0.179849\n",
       "ppl-ref_prod         0.107081\n",
       "ppl-ref_dep          0.142977\n",
       "ppl-prompt_pos       0.129655\n",
       "ppl-correct          0.324922\n",
       "ppl-correct_pos      0.175772\n",
       "ppl-correct_prod     0.134920\n",
       "maxsim_15_skip       0.348486\n",
       "maxsim_30_skip       0.353502\n",
       "maxsim_50_skip       0.348165\n",
       "maxsim_15_cbw        0.356029\n",
       "maxsim_30_cbw        0.362005\n",
       "maxsim_50_cbw        0.355592\n",
       "lda_sim-max          0.339177\n",
       "lda_sim-min          0.190316\n",
       "lda_sim-avg          0.284269\n",
       "ngram_match          0.199233\n",
       "ngram_match-lem      0.188534\n",
       "parse_score-ratio    0.115689\n",
       "length_ratio         0.108930\n",
       "Name: language, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "noun_error_count      -0.112632\n",
       "Article_error_count   -0.191626\n",
       "edit_distance         -0.428848\n",
       "edit_pattern-JJ-NN    -0.102209\n",
       "edit_pattern-NN-VB    -0.124359\n",
       "edit_pattern-NNS-NN   -0.114270\n",
       "edit_pattern-OO-CD    -0.108726\n",
       "edit_pattern-OO-DT    -0.132904\n",
       "edit_pattern-OO-FW    -0.101921\n",
       "edit_pattern-OO-IN    -0.144808\n",
       "edit_pattern-OO-JJ    -0.135984\n",
       "edit_pattern-OO-NN    -0.201263\n",
       "edit_pattern-OO-TO    -0.183642\n",
       "edit_pattern-OO-VB    -0.135089\n",
       "edit_pattern-OO-VBP   -0.135041\n",
       "edit_pattern-VB-VBP   -0.102068\n",
       "ngram_unseen-1        -0.401850\n",
       "ngram_unseen-2        -0.434220\n",
       "length_under-min      -0.235041\n",
       "length_above-max      -0.118725\n",
       "prompt_missing        -0.414655\n",
       "prompt_missing-pct    -0.340973\n",
       "prompt_DT             -0.135631\n",
       "prompt_IN             -0.232908\n",
       "prompt_NN             -0.316479\n",
       "prompt_VB             -0.243354\n",
       "Name: language, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ppl-ref',\n",
       " 'ppl-ref_pos',\n",
       " 'ppl-ref_prod',\n",
       " 'ppl-ref_dep',\n",
       " 'ppl-prompt_pos',\n",
       " 'ppl-correct',\n",
       " 'ppl-correct_pos',\n",
       " 'ppl-correct_prod',\n",
       " 'maxsim_15_skip',\n",
       " 'maxsim_30_skip',\n",
       " 'maxsim_50_skip',\n",
       " 'maxsim_15_cbw',\n",
       " 'maxsim_30_cbw',\n",
       " 'maxsim_50_cbw',\n",
       " 'lda_sim-max',\n",
       " 'lda_sim-min',\n",
       " 'lda_sim-avg',\n",
       " 'ngram_match',\n",
       " 'ngram_match-lem',\n",
       " 'parse_score-ratio',\n",
       " 'length_ratio',\n",
       " 'noun_error_count',\n",
       " 'Article_error_count',\n",
       " 'edit_distance',\n",
       " 'edit_pattern-JJ-NN',\n",
       " 'edit_pattern-NN-VB',\n",
       " 'edit_pattern-NNS-NN',\n",
       " 'edit_pattern-OO-CD',\n",
       " 'edit_pattern-OO-DT',\n",
       " 'edit_pattern-OO-FW',\n",
       " 'edit_pattern-OO-IN',\n",
       " 'edit_pattern-OO-JJ',\n",
       " 'edit_pattern-OO-NN',\n",
       " 'edit_pattern-OO-TO',\n",
       " 'edit_pattern-OO-VB',\n",
       " 'edit_pattern-OO-VBP',\n",
       " 'edit_pattern-VB-VBP',\n",
       " 'ngram_unseen-1',\n",
       " 'ngram_unseen-2',\n",
       " 'length_under-min',\n",
       " 'length_above-max',\n",
       " 'prompt_missing',\n",
       " 'prompt_missing-pct',\n",
       " 'prompt_DT',\n",
       " 'prompt_IN',\n",
       " 'prompt_NN',\n",
       " 'prompt_VB']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_corr = train_ml.corr()\n",
    "CORR_CUT = 0.1\n",
    "\n",
    "tb_l = tb_corr['language'].drop(['language', 'meaning'])\n",
    "display(tb_l[tb_l > CORR_CUT])\n",
    "display(tb_l[tb_l < -1 * CORR_CUT])\n",
    "col_l = list(tb_l[tb_l > CORR_CUT].index) + list(tb_l[tb_l < -1 * CORR_CUT].index)\n",
    "display(col_l)\n",
    "len(col_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert pandas DF to numpy array\n",
    "\n",
    "def get_langauge_X(df):\n",
    "    X = df.loc[:, col_l].values\n",
    "    return X\n",
    "\n",
    "def get_langauge_y(df):\n",
    "    return df['language'].values\n",
    "\n",
    "def get_meaning_y(df):\n",
    "    return df['meaning'].values\n",
    "\n",
    "def get_both_y(df):\n",
    "    return df.loc[:,['meaning', 'language']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the entire train to train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5106, 47)\n",
      "(5106,)\n",
      "(1277, 47)\n",
      "(1277,)\n",
      "(5106,)\n",
      "(1277,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = get_langauge_X(train_ml)\n",
    "y = get_both_y(train_ml)\n",
    "\n",
    "lang_train_X, lang_test_X, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "# from two labels to one label\n",
    "lang_train_y = y_train[:,1]\n",
    "meaning_train_y = y_train[:,0]\n",
    "lang_test_y = y_test[:,1]\n",
    "meaning_test_y = y_test[:,0]\n",
    "\n",
    "print(lang_train_X.shape)\n",
    "print(lang_train_y.shape)\n",
    "\n",
    "print(lang_test_X.shape)\n",
    "print(lang_test_y.shape)\n",
    "\n",
    "print(meaning_train_y.shape)\n",
    "print(meaning_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-norm all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing.data import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1)) # for SVM\n",
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5106, 47)\n",
      "(5106,)\n",
      "(1277, 47)\n",
      "(1277,)\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(lang_train_X)\n",
    "lang_train_X = scaler.transform(lang_train_X)\n",
    "lang_test_X = scaler.transform(lang_test_X)\n",
    "\n",
    "print(lang_train_X.shape)\n",
    "print(lang_train_y.shape)\n",
    "print(lang_test_X.shape)\n",
    "print(lang_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle all year18 numpy arraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/numpy/year18.pkl', 'wb') as pf:\n",
    "    pickle.dump([lang_train_X,\n",
    "                 lang_train_y,\n",
    "                 lang_test_X,\n",
    "                 lang_test_y,\n",
    "                 meaning_train_y,\n",
    "                 meaning_test_y], pf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
